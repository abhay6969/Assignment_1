{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d1171-9a5e-4eaa-a9c1-9d7f9d78e3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 1:\n",
    "Missing Values in a Dataset are values whose values are either missing because of some issue.It is essential to handle missing values\n",
    "as they have an significant impact on the accuracy and reliability of the model.\n",
    "Some algorithms which are not affected by missing values:\n",
    "1. Decision Trees\n",
    "2. Random Forest\n",
    "3. KNN\n",
    "4. Naive Bayes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7da23ee-95f4-4d14-b028-e7d5ba6dbcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values  survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Missing Values  survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "deck           0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Answer 2:\n",
    "Techniques used to handle missing values:\n",
    "1. Dropping rows with missing values\n",
    "2. Droping Columns with missing values\n",
    "3. Mean/Median Imputation\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "print(\"Missing Values \" ,df.isna().sum())\n",
    "#. Dropping rows with missing values\n",
    "df = df.dropna()\n",
    "print(\"Missing Values \" ,df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabb992b-5b01-4a17-8bc3-3103673e277e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values  survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Missing Values  survived      0\n",
      "pclass        0\n",
      "sex           0\n",
      "sibsp         0\n",
      "parch         0\n",
      "fare          0\n",
      "class         0\n",
      "who           0\n",
      "adult_male    0\n",
      "alive         0\n",
      "alone         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "print(\"Missing Values \" ,df.isna().sum())\n",
    "#.  Droping Columns with missing values\n",
    "df = df.dropna(axis = 1)\n",
    "print(\"Missing Values \" ,df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dbc1c63-1c61-4a6c-9568-225c8cecbe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values  survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "Missing Values  survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age              0\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "print(\"Missing Values \" ,df.isna().sum())\n",
    "#.  Droping Columns with missing values\n",
    "df.age = df.age.fillna(df.age.mean())\n",
    "print(\"Missing Values \" ,df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e3afe6-83c9-4365-878d-b594d345c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 3:\n",
    "Imbalanced data is a state where the instance of data of one particular type is more than the other.\n",
    "Model created with imbalanced data will always predict the larger class. Such a model is known\n",
    "as Dumb Model. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8397bbd7-b6c0-46e4-a2c2-3d2e13a782d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 4:\n",
    "Upsampling:\n",
    "Upsampling is when we create more samples of the data of the class with fewer instances. It is \n",
    "used when the Data is Imbalanced and a particular category has fewer instances then the other.\n",
    "\n",
    "Downsampling:\n",
    "Downsampling involves reducing the number of samples in a  data set by selecting a subset of the \n",
    "original data. This can be done by applying a low-pass filter to the original signal and then \n",
    "discarding some of the samples. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348519db-e7d4-4893-8360-24755b775607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 5:\n",
    "Data augmentation is a technique used in machine learning to artificially increase the size of a\n",
    "dataset by creating additional samples that are similar to the original data.This can be \n",
    "particularly useful when working with limited datasets, as it allows us to generate new data \n",
    "points without collecting additional data.\n",
    "SMOTE (Synthetic Minority Over-sampling Technique) is a data augmentation technique used in machine\n",
    "learning for imbalanced datasets. In an imbalanced dataset, one class of the target variable has \n",
    "significantly fewer samples than the other class. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233c42f2-cac2-49db-a569-77bf0b60b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 6:\n",
    "Outliers are data points that are significantly different from the other data points in a dataset.\n",
    "They can occur due to measurement errors or data entry errors. Outliers \n",
    "can have a significant impact on the statistical analysis and modeling of data, leading to \n",
    "inaccurate results and biased conclusions.\n",
    "It is essential to handle outliers in a dataset because  Outliers can affect the calculation of\n",
    "statistics such as mean, standard deviation, and correlation, leading to misleading results. They \n",
    "can also cause issues in machine learning models, where they may be given too much importance and\n",
    "lead to overfitting or reduced performance.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2616d-9633-4fdd-8fda-9f7ade620d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 7:\n",
    "1. Removal: One approach to handling missing data is to remove the rows or columns that contain\n",
    "missing data.\n",
    "2. Imputation: Another approach to handling missing data is to impute the missing values with \n",
    "estimated values. This can involve using statistical methods such as mean, median, or mode\n",
    "imputation, where missing values are replaced with the mean, median, or mode of the non-missing\n",
    "values in the same column.\n",
    "3. Domain knowledge: In some cases, missing data can be inferred from domain knowledge or external\n",
    "sources. For example, missing data on a customer's income can be inferred from their occupation or\n",
    "industry.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c37972-0ada-4eb4-9e3f-47408d4798ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 8:\n",
    "1. Correlation analysis: An approach to identifying patterns in missing data is to examine the \n",
    "correlation between missing values and other variables in the dataset. If missing values are \n",
    "correlated with other variables, this suggests that there is a pattern to the missing data.\n",
    "2. Visual inspection: One approach to identifying patterns in missing data is to plot the missing data \n",
    "to visualize any patterns. For example, a heatmap can be used to display the missingness of the data,\n",
    "with missing values represented by a different color.\n",
    "3. Statistical tests such as Little's test or Chi-squared test can be used to determine if the missing\n",
    "data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c3694-1794-4bf9-b9e3-70385c9ab62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 9:\n",
    "Resampling techniques such as oversampling the minority class or undersampling the majority class\n",
    "can be used to balance the dataset. Oversampling techniques such as Synthetic Minority Over-sampling\n",
    "Technique (SMOTE) and Adaptive Synthetic Sampling (ADASYN) can be used to create synthetic samples\n",
    "of the minority class, while undersampling techniques such as Random Under-sampling and Tomek Links\n",
    "can be used to randomly remove samples from the majority class.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b760c-204e-4245-87b6-36027164521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 10:\n",
    "1. Random under-sampling: In this technique, random samples are removed from the majority class to\n",
    "balance the dataset. This method can be simple but may result in a loss of information and potential\n",
    "bias.\n",
    "2. Tomek links: Tomek links are pairs of samples from different classes that are closest to each other.\n",
    "Removing the majority samples from these pairs can improve the performance of the classifier.\n",
    "3. NearMiss: NearMiss is a group of under-sampling methods that selects samples from the majority class\n",
    "based on their distance to the minority class. It selects the samples that are closest to the \n",
    "minority class.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d0eb3-a4df-4bee-9b3f-9189d9cbb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Answer 11:\n",
    "1. Random over-sampling: In this technique, random samples are duplicated from the minority class to \n",
    "balance the dataset. This method can be simple but may result in overfitting and potential bias.\n",
    "\n",
    "2. Synthetic Minority Over-sampling Technique (SMOTE): This technique creates synthetic samples\n",
    "by interpolating between minority class samples. It randomly selects a minority class sample and\n",
    "finds its k-nearest neighbors. It then creates new samples by interpolating between the minority \n",
    "class sample and its k-nearest neighbors.\n",
    "\n",
    "3. Adaptive Synthetic Sampling (ADASYN): This technique is similar to SMOTE but creates more \n",
    "synthetic samples in regions where the minority class is under-represented.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
